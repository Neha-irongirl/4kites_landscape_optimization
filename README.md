# Hallucination_detection_in_LLMs
A systematic approach to detect and quantify hallucinations in LLM-generated content, with focus on creating verifiable benchmarks and automated detection methods that don't rely solely on ground truth datasets.
